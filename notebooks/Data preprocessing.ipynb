{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к данным\n",
    "raw_data_dir = '../data/raw/'\n",
    "output_path = '../data/processed/context_answer.csv'\n",
    "character = 'House'\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Функция для очистки текста'''\n",
    "    text = re.sub(r'\\[.*?\\]|\\(.*?\\)', '', text)  # Удаление текста в скобках \n",
    "    text = re.sub(r'\\s+', ' ', text)  # Удаление лишних пробелов\n",
    "    text = text.strip()  # Удаление пробелов в начале и конце\n",
    "    # text = text.lower()  # Приведение к нижнему регистру (опционально)\n",
    "    # text = text.translate(str.maketrans('', '', string.punctuation))  # Удаление пунктуации (опционально)\n",
    "    return text\n",
    "\n",
    "# Загрузка всех CSV-файлов из директории\n",
    "all_files = [os.path.join(raw_data_dir, f) for f in os.listdir(raw_data_dir) if f.endswith('.csv')]\n",
    "df_list = []\n",
    "for file in all_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "        df_list.append(df)\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file, encoding='utf-8')\n",
    "        df_list.append(df)\n",
    "full_text = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Очистка данных\n",
    "full_clean_text = full_text.dropna(subset=['name', 'line']).reset_index(drop=True)\n",
    "full_clean_text.loc[:, 'line'] = full_clean_text['line'].apply(clean_text)\n",
    "\n",
    "# Формирование пар \"контекст-ответ\"\n",
    "min_length = 5  # Минимальная длина реплики\n",
    "pairs = []\n",
    "for i in range(1, len(full_clean_text)):\n",
    "    if full_clean_text.loc[i, 'name'] == character:\n",
    "        context = full_clean_text.loc[i - 1, 'line']\n",
    "        response = full_clean_text.loc[i, 'line']\n",
    "        if context and response and len(context.split()) >= min_length and len(response.split()) >= min_length:\n",
    "            pairs.append({'context': context, 'response': response})\n",
    "pairs_df = pd.DataFrame(pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Основная информация о данных:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12329 entries, 0 to 12328\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   context   12329 non-null  object\n",
      " 1   response  12329 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 192.8+ KB\n",
      "None\n",
      "\n",
      "Пропуски в данных:\n",
      "context     0\n",
      "response    0\n",
      "dtype: int64\n",
      "\n",
      "Найденные аномальные символы: {'+', '/', '\\x97', '&', 'º', '@', '%', '*', '\\x9f', '¡', '±', '\\x89', 'é', '_', '\\x9d', '$', '{', '§', 'ï', '¿', 'Ã', '#', '\\x93', ']', '½', '³', '¢', '¯', '[', '¶'}\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/matplotlib/style/core.py:137\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     style \u001b[38;5;241m=\u001b[39m \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/matplotlib/__init__.py:866\u001b[0m, in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    865\u001b[0m rc_temp \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 866\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/matplotlib/__init__.py:843\u001b[0m, in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    842\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname)\n\u001b[0;32m--> 843\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'seaborn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m pairs_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pairs_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(remove_anomalous_characters)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Настройка стиля графиков\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseaborn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#3498db\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#e74c3c\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#2ecc71\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Синий, красный, зеленый\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m### 1. Совмещенное распределение длин реплик с KDE ###\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/matplotlib/style/core.py:139\u001b[0m, in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    137\u001b[0m         style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(style)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid package style, path of style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, URL of style file, or library style name (library \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyles are listed in `style.available`)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    143\u001b[0m filtered \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: 'seaborn' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# Основная информация\n",
    "print(\"Основная информация о данных:\")\n",
    "print(pairs_df.info())\n",
    "\n",
    "# Проверка на пропуски\n",
    "print(\"\\nПропуски в данных:\")\n",
    "print(pairs_df.isnull().sum())\n",
    "\n",
    "# Добавим столбцы с длиной реплик\n",
    "pairs_df['context_length'] = pairs_df['context'].apply(lambda x: len(x.split()))\n",
    "pairs_df['response_length'] = pairs_df['response'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Поиск и удаление аномалий\n",
    "allowed_chars = r\"[a-zA-Z0-9\\s.,!?;:'\\\"()\\-]\"  # Определим допустимые символы с помощью регулярного выражения\n",
    "anomalous_chars = set()\n",
    "\n",
    "\n",
    "def find_anomalous_characters(text):\n",
    "    anomalous_chars = set()\n",
    "    for char in text:\n",
    "        if not re.match(allowed_chars, char):\n",
    "            anomalous_chars.add(char)\n",
    "    return anomalous_chars\n",
    "\n",
    "for text in pairs_df['context']:\n",
    "    anomalous_chars.update(find_anomalous_characters(text))\n",
    "for text in pairs_df['response']:\n",
    "    anomalous_chars.update(find_anomalous_characters(text))\n",
    "\n",
    "print(\"\\nНайденные аномальные символы:\", anomalous_chars)\n",
    "\n",
    "\n",
    "def remove_anomalous_characters(text):\n",
    "    \"\"\"Функция для удаления запрещенных символов\"\"\"\n",
    "    # Используем регулярное выражение для поиска всех допустимых символов\n",
    "    cleaned_text = re.findall(allowed_chars, text)\n",
    "    # Соединяем найденные символы обратно в строку\n",
    "    return ''.join(cleaned_text)\n",
    "\n",
    "# Применим функцию ко всем репликам в DataFrame\n",
    "pairs_df['context'] = pairs_df['context'].apply(remove_anomalous_characters)\n",
    "pairs_df['response'] = pairs_df['response'].apply(remove_anomalous_characters)\n",
    "\n",
    "# Настройка стиля графиков\n",
    "plt.style.use('seaborn')\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71']  # Синий, красный, зеленый\n",
    "\n",
    "### 1. Совмещенное распределение длин реплик с KDE ###\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Гистограмма с KDE\n",
    "sns.histplot(data=pairs_df, x='context_length', color=colors[0], \n",
    "             label='Контекст', kde=True, alpha=0.5, bins=30)\n",
    "sns.histplot(data=pairs_df, x='response_length', color=colors[1], \n",
    "             label='Ответ', kde=True, alpha=0.5, bins=30)\n",
    "\n",
    "# Вертикальные линии средних значений\n",
    "mean_ctx = pairs_df['context_length'].mean()\n",
    "mean_resp = pairs_df['response_length'].mean()\n",
    "plt.axvline(mean_ctx, color=colors[0], linestyle='--', linewidth=2)\n",
    "plt.axvline(mean_resp, color=colors[1], linestyle='--', linewidth=2)\n",
    "\n",
    "# Аннотации\n",
    "plt.text(mean_ctx+2, plt.ylim()[1]*0.8, \n",
    "         f'Среднее: {mean_ctx:.1f}', color=colors[0], fontsize=12)\n",
    "plt.text(mean_resp+2, plt.ylim()[1]*0.7, \n",
    "         f'Среднее: {mean_resp:.1f}', color=colors[1], fontsize=12)\n",
    "\n",
    "plt.title('Совмещенное распределение длин реплик', fontsize=14)\n",
    "plt.xlabel('Длина в словах', fontsize=12)\n",
    "plt.ylabel('Частота', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### 2. Топ-слов в виде горизонтальных барчартов ###\n",
    "def plot_top_words(word_counts, title, color):\n",
    "    words, counts = zip(*word_counts)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bars = plt.barh(words[::-1], counts[::-1], color=color, alpha=0.7)  # reverse для сортировки\n",
    "    \n",
    "    # Аннотации значений\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + 5, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{width}', va='center', fontsize=10)\n",
    "    \n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('Количество употреблений', fontsize=12)\n",
    "    plt.grid(True, axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_top_words(top_context_words, 'Топ-20 слов в контекстах', colors[0])\n",
    "plot_top_words(top_response_words, 'Топ-20 слов в ответах', colors[1])\n",
    "\n",
    "### 3. Круговая диаграмма уникальности ###\n",
    "unique_stats = {\n",
    "    'Уникальные контексты': unique_contexts,\n",
    "    'Уникальные ответы': unique_responses,\n",
    "    'Дубликаты пар': duplicates\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "values = list(unique_stats.values())\n",
    "labels = [f'{k}\\n({v} | {v/sum(values)*100:.1f}%)' for k, v in unique_stats.items()]\n",
    "\n",
    "plt.pie(values, labels=labels, colors=colors, autopct='', \n",
    "        startangle=90, shadow=True, explode=(0.1, 0, 0))\n",
    "plt.title('Распределение уникальности данных', fontsize=14)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### 4. Ящики с усами для длин ###\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=pairs_df[['context_length', 'response_length']], \n",
    "            palette=colors[:2], showfliers=False)\n",
    "\n",
    "# Аннотации медиан\n",
    "medians = pairs_df[['context_length', 'response_length']].median().values\n",
    "for xtick in plt.xticks()[0]:\n",
    "    plt.text(xtick, medians[xtick]+1, f'Медиана: {medians[xtick]:.1f}', \n",
    "             ha='center', color=colors[xtick], fontsize=12)\n",
    "\n",
    "plt.title('Распределение длин реплик (без выбросов)', fontsize=14)\n",
    "plt.ylabel('Длина в словах', fontsize=12)\n",
    "plt.xticks([0, 1], ['Контексты', 'Ответы'], fontsize=12)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### 5. Скаттерплот длин контекста и ответа ###\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = sns.regplot(x='context_length', y='response_length', \n",
    "                     data=pairs_df, color=colors[2], \n",
    "                     scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\n",
    "\n",
    "# Расчет корреляции\n",
    "corr = pairs_df[['context_length', 'response_length']].corr().iloc[0,1]\n",
    "plt.text(0.95, 0.95, f'Pearson R: {corr:.2f}', \n",
    "         transform=plt.gca().transAxes, ha='right', \n",
    "         fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.title('Зависимость длины ответа от контекста', fontsize=14)\n",
    "plt.xlabel('Длина контекста', fontsize=12)\n",
    "plt.ylabel('Длина ответа', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def get_top_words(column, top_n=20):\n",
    "    \"\"\"Топ-20 слов в контекстах и ответах\"\"\"\n",
    "    all_words = ' '.join(column).split()\n",
    "    filtered_words = [word for word in all_words if word.lower() if len(word) > 3]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    return word_counts.most_common(top_n)\n",
    "\n",
    "top_context_words = get_top_words(pairs_df['context'])\n",
    "print(\"\\nТоп-20 слов в контекстах:\", top_context_words)\n",
    "\n",
    "top_response_words = get_top_words(pairs_df['response'])\n",
    "print(\"Топ-20 слов в ответах:\", top_response_words)\n",
    "\n",
    "# Уникальные реплики\n",
    "unique_contexts = pairs_df['context'].nunique()\n",
    "unique_responses = pairs_df['response'].nunique()\n",
    "\n",
    "print(f\"\\nУникальных контекстов: {unique_contexts}\")\n",
    "print(f\"Уникальных ответов: {unique_responses}\")\n",
    "\n",
    "# Поиск дубликатов\n",
    "duplicates = pairs_df.duplicated(subset=['context', 'response']).sum()\n",
    "print(f\"\\nКоличество дубликатов пар 'контекст-ответ': {duplicates}\")\n",
    "\n",
    "# Случайные примеры\n",
    "print(\"\\nСлучайные примеры пар 'контекст-ответ':\")\n",
    "print(pairs_df.sample(5))\n",
    "\n",
    "# Сохранение данных\n",
    "pairs_df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из CSV\n",
    "data_path = '../data/processed/context_answer.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Преобразование данных в JSON\n",
    "data_json = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Создаем запись с полями character, q и a\n",
    "    entry = {\n",
    "        \"character\": \"house\",  # Укажите имя персонажа\n",
    "        \"q\": row[\"context\"],      # context -> q\n",
    "        \"a\": row[\"response\"]      # response -> a\n",
    "    }\n",
    "    data_json.append(entry)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение в JSON-файл\n",
    "output_path = '../data/processed/context_answer.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Данные сохранены в {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
